{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "将train.txt进行二八划分为训练集和验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "file_path =\"data/train.txt\"\n",
    "\n",
    "user_list = []\n",
    "\n",
    "# 读取train.txt文件\n",
    "with open(file_path, \"r\") as f:\n",
    "    while True:\n",
    "        data=f.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        data=data.split('|')\n",
    "\n",
    "        user_id,rate_nums= data[0],data[1]\n",
    "        user_rate={} # 保存用户的打分表\n",
    "        for i in range(int(rate_nums)):\n",
    "            rate=f.readline()\n",
    "            rate=rate.split()\n",
    "            user_rate[rate[0]]=float(rate[1])\n",
    "        \n",
    "        user_list.append(user_rate)\n",
    "\n",
    "\n",
    "# 对train集合进行二八划分，其中20%作为验证集，80%作为训练集，验证集和中的数据用来测试模型的准确性\n",
    "def split(train_set):\n",
    "    \"\"\"\n",
    "    对train集合进行二八划分\n",
    "    \n",
    "    Args:\n",
    "        train_set:训练集\n",
    "\n",
    "    Returns:\n",
    "        train_set:训练集\n",
    "        valid_set:测试集\n",
    "    \"\"\"\n",
    "    # 设置一个种子，保证每次运行的结果一致\n",
    "    random.seed(0)\n",
    "    valid_set={}\n",
    "    for user in range(len(train_set)):\n",
    "        test={}\n",
    "        for item in train_set[user].keys():\n",
    "            if random.random()<0.2:\n",
    "                test[item]=train_set[user][item]\n",
    "        for item in test.keys():\n",
    "            del train_set[user][item]\n",
    "        valid_set[user]=test\n",
    "\n",
    "    return train_set,valid_set\n",
    "# 将处理结果写入文件中，方便不同算法读取\n",
    "\n",
    "def write_to_file(file_path,data):\n",
    "    with open(file_path,\"w\") as f:\n",
    "        for user in range(len(data)):\n",
    "            f.write(str(user)+\"|\"+str(len(data[user]))+'\\n')\n",
    "            for item in data[user].keys():\n",
    "                f.write(str(item)+\" \"+str(data[user][item])+'\\n')\n",
    "\n",
    "train_set,valid_set=split(user_list)\n",
    "write_to_file(\"data/train_set.txt\",train_set)\n",
    "write_to_file(\"data/valid_set.txt\",valid_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 协同过滤（Collaborative Filtering）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19835\n"
     ]
    }
   ],
   "source": [
    "user_average = []\n",
    "print(len(train_set))\n",
    "# 计算每个用户的平均打分\n",
    "for user in train_set:\n",
    "    sum=0\n",
    "    for item in user.keys():\n",
    "        sum+=user[item]\n",
    "    user_average.append(sum/len(user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def pearson(user1,user2,user1_id,user2_id):\n",
    "    \"\"\"\n",
    "    计算pearson correlation coefficient\n",
    "    \n",
    "    Args:\n",
    "        user1:用户1的打分列表\n",
    "        user2:用户2的打分列表\n",
    "    \n",
    "    Returns:\n",
    "        pearson相关系数\n",
    "    \n",
    "    \"\"\"\n",
    "    average1=user_average[user1_id]\n",
    "    average2=user_average[user2_id]\n",
    "    \n",
    "    # 获得共有的item\n",
    "    shared=set(user1.keys()) & set(user2.keys())\n",
    "\n",
    "    # 如果没有共同元素，返回无穷\n",
    "    if not shared:\n",
    "        return math.inf\n",
    "        \n",
    "    # 计算pearson相关系数\n",
    "    sim=0\n",
    "    temp1=0\n",
    "    temp2=0\n",
    "    for item in shared:\n",
    "        sim+=(user1[item]-average1)*(user2[item]-average2)\n",
    "        temp1+=(user1[item]-average1)**2\n",
    "        temp2+=(user2[item]-average2)**2\n",
    "        \n",
    "    if(temp1==0):\n",
    "        print(\"temp1=0\")\n",
    "    if(temp2==0):\n",
    "        print(shared)\n",
    "        for item in shared:\n",
    "            print(user1[item],user2[item],average1,average2)\n",
    "        print(\"temp2=0\")\n",
    "\n",
    "    sim=sim/((temp1**0.5)*(temp2**0.5))\n",
    "    return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'608376', '550452'}\n",
      "90.0 90.0 81.05263157894737 90.0\n",
      "90.0 90.0 81.05263157894737 90.0\n",
      "temp2=0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m         nearest[user]\u001b[38;5;241m=\u001b[39mheapq\u001b[38;5;241m.\u001b[39mnlargest(k,similarity[user],key\u001b[38;5;241m=\u001b[39msimilarity[user]\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nearest\n\u001b[1;32m---> 38\u001b[0m nearest\u001b[38;5;241m=\u001b[39m\u001b[43mcal_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(nearest)\n",
      "Cell \u001b[1;32mIn[31], line 18\u001b[0m, in \u001b[0;36mcal_similarity\u001b[1;34m(train_set)\u001b[0m\n\u001b[0;32m     16\u001b[0m     similarity[user1]\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(user1\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(train_set)):\n\u001b[1;32m---> 18\u001b[0m         similarity[user1][user2]\u001b[38;5;241m=\u001b[39m\u001b[43mpearson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43muser1\u001b[49m\u001b[43m,\u001b[49m\u001b[43muser2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity\n",
      "Cell \u001b[1;32mIn[30], line 41\u001b[0m, in \u001b[0;36mpearson\u001b[1;34m(user1, user2, user1_id, user2_id)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28mprint\u001b[39m(user1[item],user2[item],average1,average2)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp2=0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m sim\u001b[38;5;241m=\u001b[39m\u001b[43msim\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtemp2\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sim\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "# 计算两两用户的相似度\n",
    "def cal_similarity(train_set):\n",
    "    \"\"\"\n",
    "    计算每个用户其最相似的k个用户\n",
    "    \n",
    "    Args:\n",
    "        train_set:训练集\n",
    "    \n",
    "    Returns:\n",
    "        similarity:相似度矩阵\n",
    "    \"\"\"\n",
    "    similarity={}\n",
    "    for user1 in range(len(train_set)):\n",
    "        similarity[user1]={}\n",
    "        for user2 in range(user1+1,len(train_set)):\n",
    "            similarity[user1][user2]=pearson(train_set[user1],train_set[user2],user1,user2)\n",
    "    return similarity\n",
    "\n",
    "# 为每个用户找最相似的k个用户\n",
    "def find_k_nearest(similarity,k):\n",
    "    \"\"\"\n",
    "    为每个用户找最相似的k个用户\n",
    "    \n",
    "    Args:\n",
    "        similarity:相似度矩阵\n",
    "        k:最相似的k个用户\n",
    "    \n",
    "    Returns:\n",
    "        nearest:最相似的k个用户\n",
    "    \"\"\"\n",
    "    nearest={}\n",
    "    for user in similarity.keys():\n",
    "        nearest[user]=heapq.nlargest(k,similarity[user],key=similarity[user].get)\n",
    "    return nearest\n",
    "\n",
    "nearest=cal_similarity(train_set)\n",
    "print(nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
