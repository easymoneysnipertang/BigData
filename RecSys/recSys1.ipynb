{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System 1\n",
    "- collaborative filtering (user-based)\n",
    "- collaborative filtering (item-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    # 读取train.txt格式的数据，返回字典\n",
    "    data = {}\n",
    "    with open(path, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline().strip()\n",
    "            if not line:  # EOF\n",
    "                break\n",
    "            # 读取user_id和rate_num\n",
    "            user_id, rate_num = line.split('|')\n",
    "            rate_num = int(rate_num)\n",
    "            user_id = int(user_id)\n",
    "            # 读取用户的评分数据\n",
    "            rate_data = {}\n",
    "            for i in range(rate_num):\n",
    "                item_id, score = f.readline().strip().split()\n",
    "                item_id = int(item_id)\n",
    "                score = int(score)\n",
    "                rate_data[item_id] = score\n",
    "            # 保存该用户的数据\n",
    "            data[user_id] = rate_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data): 19835\n"
     ]
    }
   ],
   "source": [
    "train_path =\"data/train_data.txt\"\n",
    "train_data = read_data(train_path)\n",
    "print(\"len(train_data):\", len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_data): 19835\n"
     ]
    }
   ],
   "source": [
    "valid_path =\"data/validate_data.txt\"\n",
    "valid_data = read_data(valid_path)\n",
    "print(\"len(valid_data):\", len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### μ : overall mean rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_avg: 49.471345245393245\n"
     ]
    }
   ],
   "source": [
    "# 计算全局平均分\n",
    "def cal_global_avg(data):\n",
    "    sum_score = 0\n",
    "    sum_num = 0\n",
    "    for user_id, rate_data in data.items():\n",
    "        sum_score += sum(rate_data.values())\n",
    "        sum_num += len(rate_data)\n",
    "    return sum_score / sum_num\n",
    "\n",
    "global_avg = cal_global_avg(train_data)\n",
    "print(\"global_avg:\", global_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b_x : rating deviation of user x (ave.rating of user x - μ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_bias: (547, 50.528654754606755)\n",
      "min_bias: (413, -49.471345245393245)\n",
      "average_bias: 20.3759866979849\n"
     ]
    }
   ],
   "source": [
    "# 统计每个用户的平均评分，用户偏差\n",
    "def cal_user_bias(data, average_score):\n",
    "    # 每个用户的平均评分\n",
    "    user_average_score = {}\n",
    "    for user_id, rate_data in data.items():\n",
    "        total_score = 0\n",
    "        for score in rate_data.values():\n",
    "            total_score += score\n",
    "        user_average_score[user_id] = total_score / len(rate_data)\n",
    "    # 每个用户与全局平均评分的偏差\n",
    "    user_bias = {}\n",
    "    for user_id, u_ave_score in user_average_score.items():\n",
    "        user_bias[user_id] = u_ave_score - average_score\n",
    "    # 最小偏差，最大偏差，平均偏差\n",
    "    max_bias = max(user_bias.items(), key=lambda x: x[1])\n",
    "    min_bias = min(user_bias.items(), key=lambda x: x[1])\n",
    "    total_bias = 0\n",
    "    for bias in user_bias.values():\n",
    "        total_bias += bias\n",
    "    average_bias = total_bias / len(user_bias)\n",
    "    return user_average_score, user_bias, max_bias, min_bias, average_bias\n",
    "\n",
    "user_average_score, user_bias, max_bias, min_bias, average_bias = cal_user_bias(train_data, global_avg)\n",
    "print(\"max_bias:\", max_bias)\n",
    "print(\"min_bias:\", min_bias)\n",
    "print(\"average_bias:\", average_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b_i : rating deviation of item i (ave.rating of item i - μ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_bias: (319866, 50.528654754606755)\n",
      "min_bias: (112993, -49.471345245393245)\n",
      "average_bias: -5.650348061258569\n"
     ]
    }
   ],
   "source": [
    "# 统计每个物品的平均评分，物品偏差\n",
    "def cal_item_bias(data, average_score):\n",
    "    # 统计物品得分\n",
    "    item_scores = {}\n",
    "    for user_id, rate_data in data.items():\n",
    "        for item_id, score in rate_data.items():\n",
    "            if item_id in item_scores:\n",
    "                item_scores[item_id].append(score)\n",
    "            else:\n",
    "                item_scores[item_id] = [score]\n",
    "    # 计算物品平均得分\n",
    "    item_average_score = {}\n",
    "    for item_id, scores in item_scores.items():\n",
    "        item_average_score[item_id] = sum(scores) / len(scores)\n",
    "    # 计算物品偏差\n",
    "    item_bias = {}\n",
    "    for item_id, i_ave_score in item_average_score.items():\n",
    "        item_bias[item_id] = i_ave_score - average_score\n",
    "    # 最大偏差，最小偏差，平均偏差\n",
    "    max_bias = max(item_bias.items(), key=lambda x: x[1])\n",
    "    min_bias = min(item_bias.items(), key=lambda x: x[1])\n",
    "    total_bias = 0\n",
    "    for bias in item_bias.values():\n",
    "        total_bias += bias\n",
    "    average_bias = total_bias / len(item_bias)\n",
    "    return item_average_score, item_bias, max_bias, min_bias, average_bias\n",
    "\n",
    "item_average_score, item_bias, max_bias, min_bias, average_bias = cal_item_bias(train_data, global_avg)\n",
    "print(\"max_bias:\", max_bias)\n",
    "print(\"min_bias:\", min_bias)\n",
    "print(\"average_bias:\", average_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_data: 5\n"
     ]
    }
   ],
   "source": [
    "baseline_data = {\n",
    "    \"global_avg\": global_avg,\n",
    "    \"user_average_score\": user_average_score,\n",
    "    \"user_bias\": user_bias,\n",
    "    \"item_average_score\": item_average_score,\n",
    "    \"item_bias\": item_bias\n",
    "}\n",
    "\n",
    "with open(\"models/baseline_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(baseline_data, f)\n",
    "\n",
    "print(\"baseline_data:\", len(baseline_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(data, model):\n",
    "    rmse, count = 0.0, 0\n",
    "    for user_id, rate_data in data.items():\n",
    "        for item_id, score in rate_data.items():\n",
    "            predict = model.predict(user_id, item_id)\n",
    "            rmse += (predict - score) ** 2\n",
    "            count += 1\n",
    "    rmse = np.sqrt((rmse / count))\n",
    "    return rmse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collaborative filtering (user-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate similarity between users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def pearson(x, y, x_ave, y_ave):\n",
    "    \"\"\"\n",
    "    calculate pearson correlation coefficient\n",
    "    Args:\n",
    "        x: the score list of x (user1)\n",
    "        y: the score list of y (user2)\n",
    "        x_ave: the average score of x (user1)\n",
    "        y_ave: the average score of y (user2)\n",
    "    Returns:\n",
    "        sim(x, y): the pearson correlation coefficient between x and y\n",
    "    \"\"\"\n",
    "    # 找到两个用户共同评分的物品\n",
    "    shared_items = set(x.keys()) & set(y.keys())\n",
    "\n",
    "    # 如果没有共同元素，返回0\n",
    "    if not shared_items:\n",
    "        return 0\n",
    "\n",
    "    # 计算pearson相关系数\n",
    "    sim, sum1, sum2 = 0, 0, 0\n",
    "    for item in shared_items:\n",
    "        temp1 = x[item] - x_ave\n",
    "        temp2 = y[item] - y_ave\n",
    "        # 为了避免分母为0的情况，对将打分值做一个微调\n",
    "        if temp1 == 0:\n",
    "            temp1 = 0.1\n",
    "        if temp2 == 0:\n",
    "            temp2 = 0.1\n",
    "        sim += temp1 * temp2  # 分子\n",
    "        # 计算分母\n",
    "        sum1 += temp1**2\n",
    "        sum2 += temp2**2\n",
    "    sim = sim / ((sum1**0.5) * (sum2**0.5))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 计算两两用户的相似度\n",
    "def cal_similarity(train_set, user_average_score):\n",
    "    \"\"\"\n",
    "    calculate the similarity between users\n",
    "    Args:\n",
    "        train_set: the train data\n",
    "    Returns:\n",
    "        similarity: the similarity matrix\n",
    "    \"\"\"\n",
    "    similarity = {key:{} for key in train_set.keys()}\n",
    "    for i, user1 in tqdm(enumerate(train_set.keys()), desc=\"Outer Loop\"):\n",
    "        for j, user2 in enumerate(list(train_set.keys())[i+1:], start=i+1):\n",
    "            pearson_sim = pearson(train_set[user1], train_set[user2], user_average_score[user1], user_average_score[user2])\n",
    "            similarity[user1][user2] = pearson_sim\n",
    "            similarity[user2][user1] = pearson_sim\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer Loop: 19835it [1:00:12,  5.49it/s] \n"
     ]
    }
   ],
   "source": [
    "similarity = cal_similarity(train_data, user_average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存相似度\n",
    "similarity_path = \"models/similarity.pkl\"\n",
    "with open(similarity_path, \"wb\") as f:\n",
    "    pickle.dump(similarity, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate rating r_xi as the weighted average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_neighbors = {}\n",
    "# 协同过滤算法 (user的好像不用baseline，没说咋用)\n",
    "def cf_user_predict(user_id, item_list, data, similarity, user_average_score, neighbor_k):\n",
    "    neighbor = sorted(similarity[user_id], key=lambda x: similarity[user_id][x], reverse=True)\n",
    "    sorted_neighbors[user_id] = neighbor\n",
    "    score={}\n",
    "    for item_id in item_list:\n",
    "        num=0\n",
    "        index=0\n",
    "        predict=0\n",
    "        sum=0\n",
    "        while index<len(neighbor):\n",
    "            if num>=neighbor_k:\n",
    "                break\n",
    "            if item_id in data[neighbor[index]]:\n",
    "                if similarity[user_id][neighbor[index]]<0:\n",
    "                    break\n",
    "                num+=1\n",
    "                predict+=similarity[user_id][neighbor[index]]*(data[neighbor[index]][item_id])\n",
    "                sum+=similarity[user_id][neighbor[index]]\n",
    "            index+=1\n",
    "        if sum!=0:\n",
    "            predict=predict/sum\n",
    "        else:\n",
    "            predict=user_average_score[user_id]\n",
    "        score[item_id]=predict\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_path = \"data/validate_data.txt\"\n",
    "valid_data = read_data(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users: 100%|██████████| 19835/19835 [1:28:02<00:00,  3.76it/s]  \n"
     ]
    }
   ],
   "source": [
    "RMSE=0\n",
    "num=0\n",
    "for user in tqdm(valid_data.keys(), desc=\"Processing users\"):\n",
    "    item_list=list(valid_data[user].keys())\n",
    "    predict=cf_user_predict(user,item_list,train_data,similarity,user_average_score,10)\n",
    "    for item in item_list:\n",
    "        RMSE+=(predict[item]-valid_data[user][item])**2\n",
    "        num+=1\n",
    "RMSE=(RMSE/num)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.889065303098945\n"
     ]
    }
   ],
   "source": [
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存相似度和排序后的相似用户\n",
    "sorted_neighbors_path = \"models/sorted_neighbors.pkl\"\n",
    "\n",
    "with open(sorted_neighbors_path, \"wb\") as f:\n",
    "    pickle.dump(sorted_neighbors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m test_data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     18\u001b[0m     item_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(test_data[user]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m---> 19\u001b[0m     predict\u001b[38;5;241m=\u001b[39m\u001b[43mcf_user_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43mitem_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43msimilarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43muser_average_score\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m item_list:\n\u001b[0;32m     21\u001b[0m         test_data[user][item]\u001b[38;5;241m=\u001b[39mpredict[item]\n",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m, in \u001b[0;36mcf_user_predict\u001b[1;34m(user_id, item_list, data, similarity, user_average_score, neighbor_k)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcf_user_predict\u001b[39m(user_id, item_list, data, similarity, user_average_score, neighbor_k):\n\u001b[1;32m----> 4\u001b[0m     neighbor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msimilarity\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     sorted_neighbors[user_id] \u001b[38;5;241m=\u001b[39m neighbor\n\u001b[0;32m      6\u001b[0m     score\u001b[38;5;241m=\u001b[39m{}\n",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m, in \u001b[0;36mcf_user_predict.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcf_user_predict\u001b[39m(user_id, item_list, data, similarity, user_average_score, neighbor_k):\n\u001b[1;32m----> 4\u001b[0m     neighbor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(similarity[user_id], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43msimilarity\u001b[49m[user_id][x], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     sorted_neighbors[user_id] \u001b[38;5;241m=\u001b[39m neighbor\n\u001b[0;32m      6\u001b[0m     score\u001b[38;5;241m=\u001b[39m{}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_data={}\n",
    "test_path=\"data/test.txt\"\n",
    "\n",
    "with open(test_path,\"r\") as f:\n",
    "    while True:\n",
    "        data=f.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        data=data.split('|')\n",
    "        user_id,rate_nums=int(data[0]),int(data[1])\n",
    "        user_rate={}\n",
    "        for i in range(int(rate_nums)):\n",
    "            rate=int(f.readline())\n",
    "            user_rate[rate]=0\n",
    "        test_data[user_id]=user_rate\n",
    "\n",
    "for user in test_data.keys():\n",
    "    item_list=list(test_data[user].keys())\n",
    "    predict=cf_user_predict(user,item_list,train_data,similarity,user_average_score,10)\n",
    "    for item in item_list:\n",
    "        test_data[user][item]=predict[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(file_path,data):\n",
    "    with open(file_path,\"w\") as f:\n",
    "        for user in data.keys():\n",
    "            f.write(str(user)+\"|\"+str(len(data[user]))+'\\n')\n",
    "            for item in data[user].keys():\n",
    "                f.write(str(item)+\" \"+str(data[user][item])+'\\n')\n",
    "\n",
    "write_to_file(\"data/result.txt\",test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collaborative filtering (item-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取item属性\n",
    "attribute_path = \"data\\itemAttribute.txt\"\n",
    "item_attribute = {}\n",
    "with open(attribute_path, \"r\") as f:\n",
    "    while True:\n",
    "        line = f.readline().strip()\n",
    "        if not line:\n",
    "            break\n",
    "        item_id, attribute1, attribute2= line.split('|')\n",
    "        item_id = int(item_id)\n",
    "        \n",
    "        if attribute1 == \"None\":\n",
    "            attribute1 = 0\n",
    "        else:\n",
    "            attribute1 = int(attribute1)\n",
    "            \n",
    "        if attribute2 == \"None\":\n",
    "            attribute2 = 0\n",
    "        else:\n",
    "            attribute2 = int(attribute2)\n",
    "        item_attribute[item_id] = (attribute1, attribute2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(item_attribute): 507172\n",
      "len(attribute): 71878\n"
     ]
    }
   ],
   "source": [
    "print(\"len(item_attribute):\", len(item_attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将属性相同的item放在一起\n",
    "all_attribute = {}\n",
    "for item_id, attribute in item_attribute.items():\n",
    "    if attribute[0]!=0:\n",
    "        if attribute[0] not in all_attribute:\n",
    "            all_attribute[attribute[0]] = set()\n",
    "            all_attribute[attribute[0]].add(item_id)\n",
    "            all_attribute[attribute[0]].add(attribute[0])\n",
    "        else:\n",
    "            all_attribute[attribute[0]].add(item_id)\n",
    "\n",
    "    if attribute[1]!=0:\n",
    "        if attribute[1] not in attribute:\n",
    "            all_attribute[attribute[1]] = set()\n",
    "            all_attribute[attribute[1]].add(item_id)\n",
    "            all_attribute[attribute[1]].add(attribute[1])\n",
    "        else:\n",
    "            all_attribute[attribute[1]].add(item_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422558\n",
      "227064\n"
     ]
    }
   ],
   "source": [
    "train_data={}\n",
    "valid_data={}\n",
    "\n",
    "train_path =\"data/train_data.txt\"\n",
    "valid_path =\"data/validate_data.txt\"\n",
    "\n",
    "with open(train_path, \"r\") as f:\n",
    "    while True:\n",
    "        data=f.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        data=data.split('|')\n",
    "        user_id,rate_nums= int(data[0]),data[1]\n",
    "        for i in range(int(rate_nums)):\n",
    "            rate=f.readline()\n",
    "            rate=rate.split()\n",
    "            item_id=int(rate[0])\n",
    "            if item_id not in train_data:\n",
    "              train_data[item_id]={}\n",
    "            train_data[item_id][user_id]=float(rate[1])\n",
    "\n",
    "with open(valid_path,\"r\") as f:\n",
    "    while True:\n",
    "        data=f.readline()\n",
    "        if not data:\n",
    "            break;\n",
    "        data=data.split('|')\n",
    "        user_id,rate_nums=int(data[0]),data[1]\n",
    "        for i in range(int(rate_nums)):\n",
    "            rate=f.readline()\n",
    "            rate=rate.split()\n",
    "            item_id=int(rate[0])\n",
    "            if item_id not in valid_data:\n",
    "              valid_data[item_id]={}\n",
    "            valid_data[item_id][user_id]=float(rate[1])\n",
    "# 输出user_list的大小\n",
    "print(len(train_data))\n",
    "# 输出valid_list的大小\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复用user的pearson相关系数，传参的时候传item即可\n",
    "def pearson(item1,item2,average1,average2):\n",
    "    \"\"\"\n",
    "    计算pearson correlation coefficient\n",
    "    Args:\n",
    "        user1:用户1的打分列表\n",
    "        user2:用户2的打分列表\n",
    "    Returns:\n",
    "        pearson相关系数\n",
    "    \"\"\"\n",
    "    # 获得共有的item\n",
    "    shared=set(item1.keys()) & set(item2.keys())\n",
    "\n",
    "    # 如果没有共同元素，返回无穷\n",
    "    if not shared:\n",
    "        return 0\n",
    "\n",
    "    # 计算pearson相关系数\n",
    "    sim=0\n",
    "    sum1=0\n",
    "    sum2=0\n",
    "    for user in shared:\n",
    "        temp1=item1[user]-average1\n",
    "        temp2=item2[user]-average2\n",
    "        # 为了避免分母为0的情况，对将打分值做一个微调\n",
    "        if temp1==0:\n",
    "            temp1=0.1\n",
    "        if temp2==0:\n",
    "            temp2=0.1\n",
    "        sim+=temp1*temp2\n",
    "        sum1+=temp1**2\n",
    "        sum2+=temp2**2\n",
    "    sim=sim/((sum1**0.5)*(sum2**0.5))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|          | 0/227064 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|          | 1/227064 [00:35<2228:23:43, 35.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.33193971777155\n",
      "36.70865876820201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|          | 2/227064 [00:45<1433:52:25, 22.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m train_data[item]:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m pear\u001b[38;5;241m=\u001b[39mpearson(train_data[item_id],train_data[item],item_average_score[item_id],item_average_score[item])\n\u001b[0;32m     47\u001b[0m sim_num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RMSE=0\n",
    "num=0\n",
    "from tqdm import tqdm\n",
    "\n",
    "for item_id, user in tqdm(valid_data.items(), desc=\"Processing items\"):\n",
    "    atrribute=(0,0)\n",
    "    if item_id in item_attribute:\n",
    "        atrribute=item_attribute[item_id]\n",
    "    neighbor=set()\n",
    "    if atrribute[0]!=0:\n",
    "        for item in all_attribute[atrribute[0]]:\n",
    "            if item in train_data and user_id in train_data[item]:\n",
    "                neighbor.add(item)\n",
    "    if atrribute[1]!=0:\n",
    "        for item in all_attribute[atrribute[1]]:\n",
    "            if item in train_data and user_id in train_data[item]:\n",
    "                neighbor.add(item)\n",
    "\n",
    "    for user_id in user.keys():\n",
    "        predict=global_avg+user_bias[user_id]\n",
    "        if item_id in train_data:\n",
    "            predict+=item_bias[item_id]\n",
    "            sum=0\n",
    "            temp_predict=0\n",
    "            for item in neighbor:\n",
    "                if item not in train_data:\n",
    "                    continue\n",
    "                pear=pearson(train_data[item_id],train_data[item],item_average_score[item_id],item_average_score[item])\n",
    "                if pear<0:\n",
    "                    continue\n",
    "                if user_id not in train_data[item]:\n",
    "                    continue\n",
    "                temp_predict+=pear*(train_data[item][user_id]-item_average_score[item])\n",
    "                sum+=pear\n",
    "            if sum==0:\n",
    "                # 计算与其他物品的相似度，并排序\n",
    "                sim={}\n",
    "                sim_num=0\n",
    "                for item in train_data.keys():\n",
    "                    if sim_num>=30:\n",
    "                        break\n",
    "                    if item==item_id:\n",
    "                        continue\n",
    "                    if user_id not in train_data[item]:\n",
    "                        continue\n",
    "                    pear=pearson(train_data[item_id],train_data[item],item_average_score[item_id],item_average_score[item])\n",
    "                    sim_num+=1\n",
    "                    sim[item]=pear\n",
    "                if len(sim)!=0:\n",
    "                    neighbor_k = sorted(sim, key=lambda x:sim[x], reverse=True)\n",
    "                    index=0\n",
    "                    sum_pearson=0\n",
    "                    sim_predict=0\n",
    "                    while index<len(neighbor_k):\n",
    "                        if index>=10:\n",
    "                            break\n",
    "                        temp_item=neighbor_k[index]\n",
    "                        sim_predict+=sim[temp_item]*(train_data[temp_item][user_id]-item_average_score[temp_item])\n",
    "                        sum_pearson+=sim[temp_item]\n",
    "                        index+=1\n",
    "                    if sum_pearson!=0:\n",
    "                        sim_predict=sim_predict/sum_pearson\n",
    "                    predict+=sim_predict\n",
    "            else:\n",
    "                temp_predict=temp_predict/sum\n",
    "                predict+=temp_predict\n",
    "        num+=1\n",
    "        RMSE+=(predict-valid_data[item_id][user_id])**2\n",
    "    print((RMSE/num)**0.5)\n",
    "RMSE=(RMSE/num)**0.5         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Average: 49.471345245393245\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "class BaselineEstimator:\n",
    "    def __init__(self, global_avg, user_bias, item_bias):\n",
    "        self.global_avg = global_avg\n",
    "        self.user_bias = user_bias\n",
    "        self.item_bias = item_bias\n",
    "        self.baseline_estimator = {}\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        for user_id, rate_data in train_data.items():\n",
    "            for item_id, score in rate_data.items():\n",
    "                self.baseline_estimator[(user_id, item_id)] = self.global_avg + self.user_bias[user_id] + self.item_bias[item_id]\n",
    "\n",
    "    def save_model(self, path=\"baseline_estimator.pkl\"):\n",
    "        # 保存自身模型\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        return self.baseline_estimator.get((user_id, item_id), self.global_avg)\n",
    "\n",
    "# # 示例：创建并保存模型\n",
    "# global_avg = 3.5\n",
    "# user_bias = {'user1': 0.1, 'user2': -0.2}\n",
    "# item_bias = {'item1': 0.05, 'item2': -0.05}\n",
    "# estimator = BaselineEstimator(global_avg, user_bias, item_bias)\n",
    "\n",
    "# train_data = {\n",
    "#     'user1': {'item1': 5, 'item2': 3},\n",
    "#     'user2': {'item1': 4, 'item2': 2}\n",
    "# }\n",
    "# estimator.fit(train_data)\n",
    "# estimator.save_model(\"models/baseline_estimator.pkl\")\n",
    "\n",
    "# 读取已经保存的模型\n",
    "baseline_path = 'models/baseline_estimator.pkl'\n",
    "with open(baseline_path, 'rb') as f:\n",
    "    baseline_data = pickle.load(f)\n",
    "\n",
    "print(\"Global Average:\", baseline_data.global_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'global_avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbaseline_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_avg\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'global_avg'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
